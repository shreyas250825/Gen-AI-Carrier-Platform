#!/usr/bin/env python3
"""
Test script for the Three-Level Intelligence Engine

This script tests all three levels of the intelligence architecture:
- Level 1: Deterministic Intelligence (always works)
- Level 2: Local AI Intelligence (Ollama - optional)
- Level 3: Cloud AI Intelligence (AWS Bedrock - pluggable)

Run this to verify the system works correctly with fallback behavior.
"""

import sys
import os
import json

# Add the backend directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

def test_intelligence_engine():
    """Test the three-level intelligence engine"""
    
    print("üß† Testing GenAI Career Intelligence Platform - Three-Level Architecture")
    print("=" * 70)
    
    try:
        from app.ai_engines.intelligence_engine import intelligence_engine
        
        # Test profile
        test_profile = {
            "role": "Software Engineer",
            "skills": ["Python", "JavaScript", "React", "Node.js", "AWS"],
            "experience_level": "Mid-Level",
            "experience_years": 4,
            "projects": [
                {"name": "E-commerce Platform", "description": "Led development of scalable web application"}
            ]
        }
        
        print(f"üìä Intelligence Engine Status:")
        print(f"  Level 1 (Deterministic): {'‚úÖ Available' if intelligence_engine.level_1_enabled else '‚ùå Unavailable'}")
        print(f"  Level 2 (Local AI):      {'‚úÖ Available' if intelligence_engine.level_2_enabled else '‚ùå Unavailable'}")
        print(f"  Level 3 (Cloud AI):      {'‚úÖ Available' if intelligence_engine.level_3_enabled else '‚ùå Unavailable'}")
        print()
        
        # Test 1: Question Generation
        print("üîç Test 1: Question Generation")
        print("-" * 30)
        
        questions = intelligence_engine.generate_questions(
            profile=test_profile,
            interview_type="mixed",
            count=3
        )
        
        print(f"Generated {len(questions)} questions:")
        for i, q in enumerate(questions, 1):
            print(f"  {i}. {q.get('text', 'N/A')}")
            print(f"     Type: {q.get('type', 'N/A')}, Difficulty: {q.get('difficulty', 'N/A')}")
        print()
        
        # Test 2: Answer Evaluation
        print("üîç Test 2: Answer Evaluation")
        print("-" * 30)
        
        test_question = "Tell me about a challenging project you worked on."
        test_answer = "I worked on an e-commerce platform where we had to handle high traffic during sales events. I implemented caching strategies and optimized database queries, which improved response time by 40%."
        
        evaluation = intelligence_engine.evaluate_answer(
            question=test_question,
            answer=test_answer,
            expected_keywords=["project", "challenge", "solution", "result"],
            profile=test_profile
        )
        
        print(f"Question: {test_question}")
        print(f"Answer: {test_answer[:100]}...")
        print(f"Evaluation:")
        print(f"  Technical Score: {evaluation.get('technical', 0)}/100")
        print(f"  Communication Score: {evaluation.get('communication', 0)}/100")
        print(f"  Confidence Score: {evaluation.get('confidence', 0)}/100")
        print(f"  Notes: {evaluation.get('short_notes', 'N/A')}")
        print()
        
        # Test 3: Aptitude Questions
        print("üîç Test 3: Aptitude Questions")
        print("-" * 30)
        
        aptitude_questions = intelligence_engine.generate_aptitude_questions(
            difficulty="medium",
            count=2
        )
        
        print(f"Generated {len(aptitude_questions)} aptitude questions:")
        for i, q in enumerate(aptitude_questions, 1):
            print(f"  {i}. [{q.get('type', 'N/A')}] {q.get('text', 'N/A')}")
            if 'options' in q:
                for j, option in enumerate(q['options'], 1):
                    print(f"     {chr(96+j)}) {option}")
        print()
        
        # Test 4: Job Fit Analysis
        print("üîç Test 4: Job Fit Analysis")
        print("-" * 30)
        
        job_description = {
            "title": "Senior Software Engineer",
            "required_skills": ["Python", "JavaScript", "React", "AWS"],
            "preferred_skills": ["Docker", "Kubernetes", "TypeScript"],
            "required_experience_years": 3
        }
        
        job_fit = intelligence_engine.calculate_job_fit(
            resume_data=test_profile,
            job_description=job_description
        )
        
        print(f"Job: {job_description['title']}")
        print(f"Overall Fit Score: {job_fit.get('overall_fit_score', 0):.1f}%")
        print(f"Skill Match: {job_fit.get('skill_match_percentage', 0):.1f}%")
        print(f"Experience Match: {job_fit.get('experience_match_percentage', 0):.1f}%")
        print(f"Role Suitability: {job_fit.get('role_suitability', 'N/A')}")
        print(f"Missing Skills: {', '.join(job_fit.get('missing_required_skills', []))}")
        print()
        
        # Test 5: Final Report Generation
        print("üîç Test 5: Final Report Generation")
        print("-" * 30)
        
        session_data = {
            "questions": questions[:2],
            "evaluations": [evaluation, evaluation],  # Duplicate for demo
            "answers": [
                {"transcript": test_answer},
                {"transcript": "I have experience with agile methodologies and team collaboration."}
            ]
        }
        
        report = intelligence_engine.generate_final_report(session_data)
        
        print(f"Report Summary: {report.get('overall_summary', 'N/A')}")
        print(f"Technical Strengths: {', '.join(report.get('technical_strengths', []))}")
        print(f"Recommendations: {', '.join(report.get('recommendations', [])[:2])}")
        print()
        
        print("‚úÖ All tests completed successfully!")
        print("üéØ The three-level intelligence architecture is working correctly.")
        print()
        print("üìù Key Features Verified:")
        print("  ‚úì Automatic fallback through intelligence levels")
        print("  ‚úì Deterministic question generation (Level 1)")
        print("  ‚úì Rule-based answer evaluation")
        print("  ‚úì Aptitude & logical reasoning assessment")
        print("  ‚úì AI-based job fit & role matching")
        print("  ‚úì Comprehensive report generation")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_ollama_integration():
    """Test Ollama integration if available"""
    print("\nü§ñ Testing Ollama Integration (Level 2)")
    print("-" * 40)
    
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"‚úÖ Ollama is running with {len(models)} models:")
            for model in models[:3]:  # Show first 3 models
                print(f"  - {model.get('name', 'Unknown')}")
            
            # Test a simple generation
            print("\nüîÑ Testing Ollama generation...")
            from app.ai_engines.intelligence_engine import intelligence_engine
            
            # Force Level 2 test by temporarily disabling Level 3
            original_level_3 = intelligence_engine.level_3_enabled
            intelligence_engine.level_3_enabled = False
            
            try:
                questions = intelligence_engine.generate_questions(
                    profile={"role": "Developer", "skills": ["Python"], "experience_level": "Junior"},
                    interview_type="technical",
                    count=1
                )
                print(f"‚úÖ Ollama generated question: {questions[0].get('text', 'N/A')[:100]}...")
            except Exception as e:
                print(f"‚ö†Ô∏è Ollama generation test failed: {e}")
            finally:
                intelligence_engine.level_3_enabled = original_level_3
                
        else:
            print("‚ùå Ollama is not responding correctly")
            
    except requests.exceptions.RequestException:
        print("‚ö†Ô∏è Ollama is not running on localhost:11434")
        print("   To test Level 2 intelligence:")
        print("   1. Install Ollama: https://ollama.ai/")
        print("   2. Run: ollama pull llama3.2:1b")
        print("   3. Start Ollama service")
    except Exception as e:
        print(f"‚ùå Ollama test failed: {e}")


if __name__ == "__main__":
    print("üöÄ GenAI Career Intelligence Platform - System Test")
    print("=" * 60)
    
    success = test_intelligence_engine()
    test_ollama_integration()
    
    if success:
        print("\nüéâ System is ready for AWS ImpactX Challenge demonstration!")
        print("üìã Next steps:")
        print("  1. Start the FastAPI server: cd backend && uvicorn app.main:app --reload")
        print("  2. Visit http://localhost:8000/docs for API documentation")
        print("  3. Test the new endpoints: /api/aptitude/* and /api/job-fit/*")
        print("  4. Check intelligence status: /api/intelligence-status")
    else:
        print("\n‚ùå System test failed. Please check the error messages above.")
        sys.exit(1)